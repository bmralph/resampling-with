---
jupyter:
  jupytext:
    notebook_metadata_filter: all,-language_info
    split_at_heading: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.6
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{r setup, include=FALSE}
source("_common.R")
```

# Ranks, quantiles and Standard Scores

Sometimes have a set of measures, in some particular units, and we want some
way to see quickly how these measures compare to one another, and how they may
compare to other measures, in different units.

Ranks are one way of having an implicit comparison between values.  Is the
value large in terms of the other values (with high rank) — or is it small (low
rank)?

We can derive quantile positions from ranks.  These are values from 0 through
1 that are closer to 1 for high rank values, and closer to 0 for low rank
values.  Each value in the data has a rank, and a corresponding quantile
position.  We can also look at the *value* corresponding to each quantile
position, and these are the *quantiles*. You will see what we mean later in the
chapter.

Ranks and quantile positions give an idea whether the measure is high or low
compared to the other values, but they do not immediately tell us whether the
measure is exceptional or unusual.  To do that, we may want to ask whether the
measure falls outside the typical range of values — that is, how the measure
compares to the *distribution* of values.  One common way of doing this is to
re-express the measures (values) as *standard scores*, where the standard score
for a particular value tells you how far the value is from the *center* of the
distribution, in terms of the typical *spread* of the distribution. Standard
values are particularly useful to allow us to *compare* different types of
measures on a standard scale.  They translate the units of measurement into
*standard* and comparable units.  We will explain this more towards the end of
the chapter.

## Household income and congressional districts

Democratic [congresswoman Marcy
Kaptur](https://en.wikipedia.org/wiki/Marcy_Kaptur) has represented the 9th
district of Ohio since 1983. Ohio's 9th district is relatively working class,
and the Democratic party has, traditionally, represented people with lower
income.  However, Kaptur has pointed out that this pattern appears to be
changing; more of the high-income congressional districts now lean Democrat,
and the Republican party is now more likely to represent lower-income
districts.  The French economist [Thomas
Piketty](https://en.wikipedia.org/wiki/Thomas_Piketty) has described this
phenomenon across several Western countries.  Voters for left parties are now
more likely to be highly educated and wealthy.  He terms this shift "Brahmin
Left Vs Merchant Right" [@piketty2018brahmin].  The data below come from
a [table Kaptur
prepared](https://s3.documentcloud.org/documents/23726766/rep-kaptur-district-chart.pdf)
that shows this pattern in the US congress. The table lists the top 20 2023
congressional districts by the median income of the households in that
district, along with their representatives and their party.

```{python echo=FALSE, eval=TRUE}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
district_income = pd.read_csv('data/congress_2023.csv')
```

```{r echo=FALSE, eval=TRUE}
d_inc <- py$district_income
colnames(d_inc)[which(names(d_inc) == "Median_Income")] <- "Median Income"
ketable(tail(d_inc, 20),
        caption = "20 most wealthy 2023 Congressional districts by household income {#tbl-district_income}")
```

You may notice right away that many of the 20 richest districts have Democratic
Party representatives.

```{python echo=FALSE, eval=TRUE}
means = district_income.groupby('Party')[['Median_Income']].mean()
demo, repub = means['Median_Income']
pct_diff = (demo - repub) / repub * 100
```

In fact, if we look at all 441 congressional districts in Kaptur's table, we
find a large difference in the average median household income for Democrat and
Republican districts; the Democrat districts are, on average, about
`r round(py$pct_diff)`% richer (@tbl-party_means).

```{r echo=FALSE, eval=TRUE}
means <- py$means
means$Median_Income <- formattable::currency(means$Median_Income, digits = 0)
names(means) <- "Mean of median household income"
ketable(means,
        caption = "Means for median household income by party {#tbl-party_means}")
```

Next we are going to tip our hand, and show how we got these data.  In previous
chapters, we had {{< var cell >}}s like this in which we enter the values we
will analyze.  These example values are from @sec-public-liquor:

```{python}
# Liquor prices for US states with private market.
priv = np.array([
    4.82, 5.29, 4.89, 4.95, 4.55, 4.90, 5.25, 5.30, 4.29, 4.85, 4.54, 4.75,
    4.85, 4.85, 4.50, 4.75, 4.79, 4.85, 4.79, 4.95, 4.95, 4.75, 5.20, 5.10,
    4.80, 4.29])
```

```{r}
# Liquor prices for US states with private market.
priv <- c(4.82, 5.29, 4.89, 4.95, 4.55, 4.90, 5.25, 5.30, 4.29, 4.85, 4.54,
          4.75, 4.85, 4.85, 4.50, 4.75, 4.79, 4.85, 4.79, 4.95, 4.95, 4.75,
          5.20, 5.10, 4.80, 4.29)
```

Now we have 441 values to enter, and it is time to introduce {{< var lang >}}s
standard tools for loading data.

### Comma-separated-values (CSV) format {#sec-csv-format}

The data we will load is in a file on disk called `data/congress_2023.csv`.
These are data from Kaptur's table in a comma-separated-values (CSV) format
file. We refer to this file with its *filename*, containing the directory
(`data/`) followed by the name of the file (`congress_2023.csv`), giving
a filename of `data/congress_2023.csv`.

The *CSV format* is a very simple text format for storing table data.  Usually,
the first line of the CSV file contains the column names of the table, and the
rest of the lines contain the row values.  As the name suggests, commas (`,`)
separate the column names in the first line, and the row values in the
following lines. If you opened the `data/congress_2023.csv` file in some editor,
such as Notepad on Windows or TextEdit on Mac, you would find that the first few
lines looked like this:

```{python echo=FALSE, eval=TRUE, results="asis"}
from pathlib import Path
backticks = '```'
lines = '\n'.join(
    Path('data/congress_2023.csv').read_text().splitlines()[:6])
# Reticulate seems to suffer with the literal backticks here.
print(f"""{backticks}
{lines}
{backticks}
""")
```

::: python

### Introducing the Pandas library {#sec-pandas-intro}

Here we start using the Pandas library to load table data into Python.

Thus far we have used the Numpy library to work with data in arrays.  Pandas is
As always with Python, when we want to use a library, we have to `import` it
first.

We have used the term *library* here, but Python uses the term *module* to
refer to libraries of code and data that you `import`.

When using Numpy, we write:

```{python}
# Import the Numpy library (module), name it "np".
import numpy as np
```

Now we will use the Pandas library (module).

We can import Pandas like this:

```{python}
# Import the Pandas library (module)
import pandas
```

As Numpy has a standard abbreviation `np`, that almost everyone writing Python
code will recognize and use, so Pandas has the standard abbreviation `pd`:

```{python}
# Import the Pandas library (module), name it "pd".
import pandas as pd
```

Pandas is the standard data science library for Python.   It is particularly
good at loading data files, and presenting them to us as a useful table-like
structure, called a *data frame*.

We start by using Pandas to load our data file:

```{python}
district_income = pd.read_csv('data/congress_2023.csv')
```

We have thus far done many operations that returned Numpy *arrays*.
`pd.read_csv` returns a Pandas *data frame*:

```{python}
type(district_income)
```

A data frame is Pandas' own way of representing a table, with columns and rows.
You can think of it as Python's version of a spreadsheet.  As strings or Numpy
arrays have *methods* (functions attached to the array values), so Pandas data
frames have methods.  These methods do things with the data frame to which they
are attached.  For example, the `head` method of the data frame shows (by
default) the first five rows in the table:

```{python}
# Show the first five rows in the data frame
district_income.head()
```

The data are in income order, sorted lowest to highest, so the first five
districts are those with the lowest household income.

We are particularly interested in the column named `Median_Income`.

You may remember the idea of *indexing*, introduced in @sec-array-indexing.
Indexing occurs when we fetch data from within a container, such as a string or
an array.  We do this by putting square brackets `[]` after the value we want
to index into, and put something inside the brackets to say what we want.

For example, to get the *first* element of the `priv` array above, we use
indexing:

```{python}
# Fetch the first element of the priv array with indexing.
# This is the element at position 0.
priv[0]
```

As you can index into strings and Numpy arrays, by using square brackets, so
you can index into Pandas data frames.  Instead of putting the *position*
between the square brackets, we can put the *column name*.  This fetches the
data from that column, returning a new thing called a Pandas *Series*.

```{python}
# Index into Pandas data frame to get one column of data.
# Notice we use a string between the square brackets, giving the column name.
income_col = district_income['Median_Income']
# The thing that comes back is of type Series.  A Series represents the
# data from a single column.
type(income_col)
```

We want to go straight to our familiar Numpy arrays, so we convert the column
of data into a Numpy array, using the `np.array` function you have already
seen:

<!---
Need to introduce indexing with slices.
-->

```{python}
# Convert column data into a Numpy array.
incomes = np.array(income_col)
# Show the first five values, by indexing with a slice.
incomes[:5]
```

:::

::: r

### Introducing R data frames

R is a data analysis language, so, as you would expect, it is particularly good
at loading data files, and presenting them to us as a useful table-like
structure, called a *data frame*.

We start by using R to load our data file.  R has a special function to do
this, called `read.csv`.

```{r}
district_income <- read.csv('data/congress_2023.csv')
```

We have thus far done many operations that returned R *vectors*. `read.csv`
returns a new thing, called a *data frame*:

```{r}
class(district_income)
```

A data frame is R's own way of representing a table, with columns and rows. You
can think of it as R's version of a spreadsheet.   Data frames are a
fundamental type in R, and there are many functions that operate on them. Among
them is the function `head` which selects (by default) the first six rows of
whatever you send it.  Here we select the first six rows of the data frame.

```{r}
# Show the first six rows in the data frame
head(district_income)
```

The data are in income order, sorted lowest to highest, so the first five
districts are those with the lowest household income.

We are particularly interested in the column named `Median_Income`.

You can fetch columns of data from a data frame by using R's `$` syntax.  The
`$` syntax means "fetch the thing named on the right of the `$` attached to the
value given to the left of the `$`".

So, to get the data for the `Median_Income` column, we can write:

```{r}
# Use $ syntax to get a column of data from a data frame.
# "fetch the Median_Income thing from district_income".
incomes = district_income$Median_Income
# The thing that comes back is our familiar R vector.
# Show the first five values, by indexing with a slice.
incomes[1:5]
```

:::

### Incomes and Ranks

We now have the `incomes` values as {{< var an_array >}}.

There are 441 values in the whole vector, one of each congressional
district:

```{python}
len(incomes)
```

```{r}
length(incomes)
```

While we are at it, let us also get the values from the "Ascending_Rank"
column, with the same procedure.  These are ranks from low to high, meaning
1 is the lowest median income, and 441 is the highest median income.

```{python}
lo_to_hi_ranks = np.array(district_income['Ascending_Rank'])
# Show the first five values, by indexing with a slice.
lo_to_hi_ranks[:5]
```

```{r}
lo_to_hi_ranks <- district_income$Ascending_Rank
# Show the first five values, by indexing with a slice.
lo_to_hi_ranks[1:5]
```

In our case, the [data frame]{.r}[DataFrame]{.python} has the `Ascending_Rank`
column with the ranks we need, but if we need the ranks and we don't have them,
we can calculate them using the [`rank` function]{.r}[`rankdata` function from
the Scipy `stats` package]{.python}.

::: python

### Introducing Scipy

Earlier in this chapter we introduced the Pandas module.  We used Pandas to
load the CSV data into Python.

Now we introduce another fundamental Python library for working with data
called Scipy.  The name Scipy comes from the compression of SCIentific PYthon,
and the library is nearly as broad as the name suggests — it is a huge
collection of functions and data that implement a wide range of scientific
algorithms.  Scipy is an umbrella package, in that it contains sub-packages,
each covering a particular field of scientific computing.  One of those
sub-packages is called `stats`, and, yes, it covers statistics.

We can get the Scipy `stats` sub-package with:

```{python}
import scipy.stats
```

but, as for Numpy and Pandas, we often `import` the package with an
abbreviation, such as:

```{python}
# Import the scipy.stats package with the name "sps".
import scipy.stats as sps
```

One of the many functions in `scipy.stats` is the `rankdata` function.

:::

### Calculating ranks

As you might expect [`rank`]{.r}[`sps.rankdata`]{.python} accepts {{< var
an_array >}} as an input argument.  Let's say that there are
[`n <- length(data)`]{.r}[`n = len(data)`]{.python}
values in the {{< var array >}} that we pass to
[`rank`]{.r}[`sps.rankdata`]{.python}.  The function returns
{{< var an_array >}}, length $n$, where the elements are the ranks of each
corresponding element in the input `data` {{< var array >}}.  A rank value of
1 corresponds the lowest value in `data` (closest to negative infinity), and
a rank of $n$ corresponds to the highest value (closest to positive infinity).

Here's an example `data` {{< var array >}} to show how
[`rank`]{.r}[`sps.rankdata`]{.python} works.

```{python}
# The data.
data = np.array([3, -1, 5, -2])
# Corresponding ranks for the data.
sps.rankdata(data)
```

```{r}
# The data.
data <- c(3, -1, 5, -2)
# Corresponding ranks for the data.
rank(data)
```

We can use [`rank`]{.r}[`sps.rankdata`]{.python} to recalculate the ranks for the
congressional median household income values.

```{python}
# Recalculate the ranks.
recalculated_ranks = sps.rankdata(incomes)
# Show the first 5 ranks.
recalculated_ranks[:5]
```

```{r}
# Recalculate the ranks.
recalculated_ranks <- rank(incomes)
# Show the first 5 ranks.
recalculated_ranks[1:5]
```

## Comparing two values in the district income data

Let us say that we have taken an interest in two particular members of
Congress: the Speaker of the House of Representatives, Republican [Kevin
McCarthy](https://en.wikipedia.org/wiki/Kevin_McCarthy), and the progressive
activist and Democrat
[Alexandria Ocasio-Cortez](https://en.wikipedia.org/wiki/Alexandria_Ocasio-Cortez).
We will refer to both using their initials: KOM for Kevin Owen McCarthy and AOC
for Alexandra Ocasio-Cortez.

By scrolling through the CSV file, or (in our case) using some simple
[R]{.r}[Pandas]{.python} code that we won't cover now, we find the rows
corresponding to McCarthy (KOM) and Ocasio-Cortez (AOC)
— @tbl-rows-of-interest.

```{python echo=FALSE, eval=TRUE}
roi = district_income[district_income['Representative']
                      .isin(['K. McCarthy', 'A. Ocasio-Cortez'])]
```

```{r echo=FALSE, eval=TRUE}
roi <- py$roi
colnames(roi)[which(names(roi) == "Median_Income")] <- "Median Income"
rownames(roi) <- NULL
ketable(roi,
        caption = "Rows for Kevin McCarthy and Alexandra Ocasio-Cortez
        {#tbl-rows-of-interest}")
```

The rows show the *rank* of each congressional district in terms of median
household income.  The districts are ordered by this rank, so we can get their
respective *indices* (positions) in the `incomes` {{< var array >}} from their
rank.
[Remember, Python's indices start at 0, whereas the ranks start at 1, so we
need to subtract 1 from the rank to get the index]{.python}

```{python}
# Rank of McCarthy's district in terms of median household income.
kom_rank = 295
# Index (position) of McCarthy's value in the "incomes" array.
# Subtract one from rank, because Python starts indices at 0 rather than 1.
kom_index = kom_rank - 1
```

```{r}
# Rank of McCarthy's district in terms of median household income.
kom_rank = 295
# Index (position) of McCarthy's value in the "incomes" vector.
# This is the same as the rank.
kom_index = kom_rank
```

Now we have the index (position) of KOM's value, we can find the household
income for his district from the `incomes` {{< var array >}}:

```{python}
# Show the median household income from McCarthy's district
# by indexing into the "incomes" array:
kom_income = incomes[kom_index]
kom_income
```

```{r}
# Show the median household income from McCarthy's district
# by indexing into the "incomes" vector:
kom_income <- incomes[kom_index]
kom_income
```

Here is the corresponding index and `incomes` value for AOC:

```{python}
# Index (position) of AOC's value in the "incomes" array.
aoc_rank = 81
aoc_index = aoc_rank - 1
# Show the median household income from AOC's district
# by indexing into the "incomes" array:
aoc_income = incomes[aoc_index]
aoc_income
```

```{r}
# Index (position) of AOC's value in the "incomes" array.
aoc_rank = 81
aoc_index = aoc_rank
# Show the median household income from AOC's district
# by indexing into the "incomes" array:
aoc_income <- incomes[aoc_index]
aoc_income
```

Notice that we fetch the same value for median household income from `incomes`
as you see in the corresponding rows.

## Comparing values with ranks and quantile positions

We have KOM's and AOC's district median household income values, but our next
question might be — how unusual are these values?

Of course, it depends what we mean by *unusual*.   We might mean, are they
greater or smaller than most of the other values?

One way of answering that question is simply looking at the rank of the values.
If the rank is lower than $\frac{441}{2} = 220.5$ then this is a district with
higher median income than most districts.  If it is greater than $220.5$ then
it has lower median income than most districts.  We see that KOM's district,
with rank `r get_var('kom_rank')` is wealthier than most, whereas AOC's
district (rank `r get_var('aoc_rank')`) is poorer than most.

But we can't interpret the ranks without remembering that there are 441 values,
so — for example - a rank of 81 represents a relatively low value one of 295 is
relatively high.

We would like some scale that tells us immediately whether this is a relatively
low or a relatively high value, without having to remembering how many values
there are.

This is a good use for *quantile positions* (QPs).  The QP of a value tells you
where the value ranks relative to the other values, on a scale from $0$ through
$1$. A QP of $0$ tells you this is the lowest-ranking value, and a QP of $1$
tells you this is the highest-ranking value.

We can calculate the QP for each rank.  Think of the low-to-high ranks as being
a line starting at 1 (the lowest rank — for the lowest median income) and going
up to 441 (the highest rank — for the highest median income).

The QP corresponding to any particular rank tells you how far along this line
the rank is.  Notice that the length of the line is the distance from the first
to the last value, so 441 - 1 = 440.

So, if the rank was $1$, then the value is at the start of the line.  It has
got $\frac{0]{440}$ of the way along the line, and the QP is $0$. If the rank is
$441$, the value is at the end of the line, it has got $\frac{440}{440}$ of the
way along the line and the QP is $1$.

Now consider the rank of $100$.  It has got $\frac{(100 - 1)}{440}$ of the way
along the line, and the QP position is `r round(99 / 440, 2)`.

More generally, we can translate the high-to-low ranks to QPs with:

```{python}
# Length of the line defining quantile positions.
# Start of line is rank 1 (quantile position 0).
# End of line is rank 441 (quantile position 1).
distance = len(lo_to_hi_ranks) - 1  # 440 in our case.
# What proportion along the line does each value get to?
quantile_positions = (lo_to_hi_ranks - 1) / distance
# Show the first five.
quantile_positions[:5]
```

```{r}
# Length of the line defining quantile positions.
# Start of line is rank 1 (quantile position 0).
# End of line is rank 441 (quantile position 1).
distance <- length(lo_to_hi_ranks) - 1  # 440 in our case.
quantile_positions <- (lo_to_hi_ranks - 1) / distance
# Show the first five.
quantile_positions[1:5]
```

Let's plot the ranks and the QPs together on the x-axis:


```{python echo=FALSE, eval=TRUE}
lo_to_hi_ranks = get_var('lo_to_hi_ranks')
incomes = get_var('incomes')
L = len(lo_to_hi_ranks)

def rank2qp(r):
    return (r - 1) / (L - 1)

def qp2rank(qp):
    return qp * (L - 1) + 1

# Plot blue crosses at data points.
def plot_ranks_qps():
    fig, ax = plt.subplots()
    ax.plot(lo_to_hi_ranks, incomes,
            color='blue', marker='+',
            linestyle=':')
    ax.set_title('Ranked median household incomes for congressional districts')
    ax.set_xlabel('Rank')
    ax.set_xticks([1, 100, 200, 300, 400, 441])
    ax.set_ylabel('Median household income')

    secax = ax.secondary_xaxis('top', functions=(rank2qp, qp2rank))
    secax.set_xlabel('Gradient position')
    return ax, secax

plot_ranks_qps();
```

The QPs for KOM and AOC tell us where their districts' incomes are in the
ranks, on a 0 to 1 scale:

```{python}
kom_quantile_position = quantile_positions[kom_index]
kom_quantile_position
```

```{r}
kom_quantile_position <- quantile_positions[kom_index]
kom_quantile_position
```

```{python}
aoc_quantile_position = quantile_positions[aoc_index]
aoc_quantile_position
```

```{r}
aoc_quantile_position <- quantile_positions[aoc_index]
aoc_quantile_position
```

If we multiply the QP by 100, we get the *percentile positions* — so the
percentile position ranges from 0 through 100.

```{python}
# Percentile positions are just quantile positions * 100
print('KOM percentile position:', kom_quantile_position * 100)
print('AOC percentile position:', aoc_quantile_position * 100)
```

```{r}
# Percentile positions are just quantile positions * 100
message('KOM percentile position: ', kom_quantile_position * 100)
message('AOC percentile position: ', aoc_quantile_position * 100)
```

Now consider one particular QP: $0.5$.  The $0.5$ QP is exactly half-way along
the line from rank $1$ to rank $441$.  In our case this corresponds to rank
$\frac{441 - 1}{2} + 1 = 221$.

```{python}
# For rank 221 we need index 220, because Python indices start at 0
print('Middle rank:', lo_to_hi_ranks[220])
print('Quantile position:', quantile_positions[220])
```

```{r}
message('Middle rank: ', lo_to_hi_ranks[221])
message('Quantile position: ', quantile_positions[221])
```

The *value* corresponding to any particular QP is the *quantile value*, or just
the *quantile* for short.  For a QP of 0.5, the *quantile* (quantile value) is:

```{python}
# Quantile value for 0.5
print('Quantile value for QP of 0.5:', incomes[220])
```

```{r}
# Quantile value for 0.5
message('Quantile value for QP of 0.5: ', incomes[221])
```

In fact we can ask {{< var lang >}} for this *value* (quantile) directly, using
the `quantile` function:

```{python}
np.quantile(incomes, 0.5)
```

```{r}
quantile(incomes, 0.5)
```

:::{.callout-note}
## `quantile` and sorting

In our case, the `incomes` data is already sorted from lowest (at position
[1]{.r}[0]{.python} in the {{< var array >}} to highest (at position
[441]{.r}[440]{.python} in the {{< var array >}}).  The `quantile` function
does not need the data to be sorted; it does its own internal sorting to do the
calculation.

For example, we could shuffle `incomes` into a random order, and still get the
same values from `quantile`.

```{python}
rnd = np.random.default_rng()
shuffled_incomes = rnd.permuted(incomes)
# Quantile still gives the same value.
np.quantile(incomes, 0.5)
```

```{r}
shuffled_incomes <- sample(incomes)
# Quantile still gives the same value.
quantile(incomes, 0.5)
```

:::


Above we have 0.5 *quantile* — the value corresponding to the 0.5 QP.

The 0.5 quantile is an interesting value.  Notice that, by the definition of
QP, exactly half of the remaining values (after excluding the 0.5 quantile
value) have lower rank, and are therefore less   than the 0.5 quantile value.
Similarly exactly half of the remaining values are greater than the 0.5
quantile.   You may recognize this as the *median* value.  This is such
a common quantile value that {{< var np_or_r >}} has a function
[`median`]{.r}[`np.median`]{.python} as a shortcut for [`quantile(data,
0.5)`]{.r}[`np.quantile(data, 0.5)`]{.python}.

```{python}
np.median(incomes)
```

Another interesting QP is 0.25.  We find the QP of 0.25 at rank:

```{python}
qp25_rank = (441 - 1) * 0.25 + 1
qp25_rank
```

```{r}
qp25_rank <- (441 - 1) * 0.25 + 1
qp25_rank
```

```{python}
# Therefore, index 110 (Python indices start from 0)
print('Rank corresponding to QP 0.25:', qp25_rank)
print('0.25 quantile value:', incomes[110])
print('0.25 quantile value using np.quantile:',
      np.quantile(incomes, 0.25))
```

```{r}
message('Rank corresponding to QP 0.25: ', qp25_rank)
message('0.25 quantile value: ', incomes[qp25_rank])
message('0.25 quantile value using quantile: ', quantile(incomes, 0.25))
```

```{python echo=FALSE, eval=TRUE}
incomes = get_var('incomes')

ax, secax = plot_ranks_qps()
qp25 = 111
q25 = np.quantile(incomes, 0.25)
x_min, x_max, y_min, y_max = ax.axis()
ax.axvline(qp25, linestyle=':', color='k')
ax.plot([qp25, x_min], [q25, q25], 'k:', label='0.25 quantile')
ax.legend()
```

Call the 0.25 quantile value $V$.  $V$ is the number such that 25% of the
*remaining* values are less than $V$, and 75% are greater.

Now let's think about the 0.01 quantile.  We don't have an *income value*
exactly corresponding to this QP, because there is no rank exactly
corresponding to the 0.01 QP.

```{python}
rank_for_qp001 = (441 - 1) * 0.01 + 1
rank_for_qp001
```

```{r}
rank_for_qp001 <- (441 - 1) * 0.01 + 1
rank_for_qp001
```

Let's have a look at the first 10 values for rank / QP and incomes:

```{python echo=FALSE, eval=TRUE}
def plot_ranks_qps_001():
    fig, ax = plt.subplots()
    ax.plot(lo_to_hi_ranks[:10], incomes[:10],
            color='blue', marker='+',
            linestyle=':')
    ax.set_title('Ranked median household incomes for congressional districts')
    ax.set_xlabel('Rank')
    ax.set_xticks([1, 2, 4, 6, 8, 10])
    ax.set_ylabel('Median household income')
    secax = ax.secondary_xaxis('top', functions=(rank2qp, qp2rank))
    secax.set_xlabel('Gradient position')
    secax.set_xticks(np.linspace(0, 0.02, 5));
    return ax, secax

plot_ranks_qps_001();
```

What then, is the quantile value for QP = 0.01?  There are various ways to
answer that question [@hyndman1996sample], but one obvious way, and the default
for {{< var np_or_r >}}, is to draw a straight line up from the matching rank
— or equivalently, down from the QP — then note where that line crosses the
lines joining the values to the left and right of the QP on the graph above,
and look across to the y-axis for the corresponding value:

```{python echo=FALSE, eval=TRUE}
rank_for_qp001 = get_var('rank_for_qp001')

ax, secax = plot_ranks_qps_001()

q001 = np.quantile(incomes, 0.01)
ax.axvline(rank_for_qp001, linestyle=':', color='k')
ax.plot([rank_for_qp001, 0], [q001, q001], 'k:', label='0.01 quantile')
ax.legend();
```

```{python}
np.quantile(incomes, 0.01)
```

```{r}
quantile(incomes, 0.01)
```

This is called the *linear* method — because it uses straight lines joining the
points to estimate the quantile value for a QP that does not correspond to
a whole-number rank.  $0000$

:::{.callout-note}
## Calculating quantiles using the linear method

We have given a graphical explanation of how to calculate the quantile for QP
that does not correspond to whole-number rank in the data. Another explanation
is to think of the quantile value as being a *weighted average* of the quantile
values for the QPs of the whole number ranks just less than, and just greater
than the QP we are interested in.  For example, let us return to the QP of
0.01.  Let us remind ourselves of the QPs, whole-number ranks and
corresponding values either side of the QP $0.01$:

| Rank | Quantile position | Value |
|------|-------------------|-------|
| 5    | 0.0099            | 37933 |
| 5.4  | 0.01              | **V** |
| 6    | 0.0113            | 40319 |

: Ranks, QPs and corresponding values around QP of 0.01

Our question is — what is $V$ in the table?  One answer is to take the average
of the two values either side of the desired QP — in this case $(37933
+ 40319) / 2$.  Notice we could also write this as $37933 * 0.5 + 40319 * 0.5$
— showing that we are giving equal weight ($0.5$) to the two values either side.

But giving both values equal  doesn't seem quite right, because the QP we want
is closer to the QP for rank 5 (and corresponding value 37933) than it is to
the QP for rank 6 (corresponding value 40319).  We should give more weight to
the rank 5 value than the rank 6 value.   Specifically the lower value is 0.4
rank units away from the QP rank we want, and the higher is 0.6 rank units
away.  So we give higher weight for shorter distance, and multiply the rank
5 value by $1 - 0.4 = 0.6$, and the rank 6 value by $1 - 0.6 = 0.4$.  Therefore
the weighted average is $37933 * 0.6 + 40319 * 0.4$ =
`r 37933 * 0.6 + 40319 * 0.4`.  This is a mathematical way to get the value we
described graphically, of tracking up from the rank of 5.4 to the line drawn
between the values for rank 5 and 6, and reading off the y-value at which this
track crosses that line.
:::




## Unusual values compared to the distribution

Now we return the problem of whether KOMs and AOCs districts are unusual in
terms of their median household incomes.  From what we have so far, we might
conclude that AOC's district is fairly poor, and KOM's district is relatively
wealthy.  But — are either of their districts *unusual* in their wealth or
poverty?

To answer that question, we have to think about the *distribution* of values.
Are either AOC's or KOM's district outside the typical spread of values for
districts?

```{python}
mean_income = np.mean(incomes)
```

```{r}
mean_income <- mean(incomes)
```

```{python echo=FALSE, eval=TRUE}
kom_income = get_var('kom_income')
aoc_income = get_var('aoc_income')

plt.hist(incomes, bins=25);
plt.title('Median household income for 2023 congressional districts');
plt.plot(kom_income, 2, 'ro', label='KOM')
plt.plot(aoc_income, 2, 'bo', label='AOC')
plt.plot(np.mean(incomes), 2, 'ko', label='Mean')
plt.legend()
```

```{python}
deviations = incomes - np.mean(incomes)
plt.hist(deviations, bins=25);
```

```{python}
deviations[kom_index]
```

```{python}
np.mean(deviations)
```

```{python}
abs_deviations = np.abs(deviations)
abs_deviations
```

```{python}
mad = np.mean(abs_deviations)
mad
```

```{python}
deviations_in_mads = deviations / mad
plt.hist(deviations_in_mads, bins=25);
```

```{python}
deviations_in_mads[kom_index]
```

```{python}
squared_deviations = deviations ** 2
squared_deviations
```

```{python}
mean_squared_deviation = np.mean(squared_deviations)
mean_squared_deviation
```

```{python}
standard_deviation = np.sqrt(mean_squared_deviation)
standard_deviation
```

```{python}
mad
```

```{python}
deviations = incomes - np.mean(incomes)
squared_deviations = deviations ** 2
mean_squared_deviation = np.mean(squared_deviations)
standard_deviation = np.sqrt(mean_squared_deviation)
standard_deviation
```

```{python}
np.std(incomes)
```

```{python}
deviations_in_stds = deviations / standard_deviation
deviations_in_stds
```

```{python}
plt.hist(deviations_in_stds, bins=25);
```

```{python}
pct_5, pct_95 = np.percentile(incomes, [5, 95])
plt.hist(incomes, bins=25)
plt.plot([pct_5, pct_95], [1, 1], 'ro')
```

```{python}
deviations_in_stds[kom_index]
```

## Standard scores to compare values on different scales

Now consider the values in @tbl-epl-points-wages.  They give the total number
of points at the end of the 2021 season (from 38 games) and the estimated wage
bill in thousands of British Pounds (£1000), for all the teams in the English
Premier League (EPL).

```{python}
from pathlib import Path

import numpy as np
import pandas as pd
pd.set_option('mode.copy_on_write', True)
```

```{python echo=FALSE, eval=TRUE}
epl = pd.read_csv('data/premier_league.csv')
```

```{r echo=FALSE, eval=TRUE}
ketable(py$epl,
        caption = "2021 points and wage bills (£1000s) for EPL teams
        {#tbl-epl-points-wages}")
```

Let's say we are a team near the middle of the league.

```{python}
import numpy as np
import pandas as pd
pd.set_option('mode.copy_on_write', True)
```

```{python}
points_wages = pd.read_csv('data/premier_league.csv')
points_wages
```

```{r}
df <- read.csv('data/premier_league.csv')
df
```

```{r}
points <- df$points
points
```

```{r}
wages <- df$wages_year
wages
```
